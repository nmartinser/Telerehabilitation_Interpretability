{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2: Clasificación de la ejecución del movimiento\n",
    "\n",
    "Este Notebook tiene como objetivo principal crear un pipeline que clasifique los gestos realizados como *correctos* o *incorrectos*. Además, aborda los siguientes aspectos clave:\n",
    "\n",
    "**Cálculo de distancias y caracterización previa de los movimientos**\n",
    "\n",
    "Se determinan las distancias entre puntos clave del cuerpo y los ángulos de distintas articulaciones en función del gesto que esté realizando el paciente. Por ejemplo, al detectar una flexión del hombro derecho, se calculan las distancias y ángulos relacionados específicamente con ese brazo.\n",
    "\n",
    "**Aprendizaje automático explicativo**\n",
    "\n",
    "Se incorpora un análisis explicativo del modelo, destacando las variables que tienen mayor influencia en las decisiones del modelo sobre el conjunto de datos completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../Imagenes/gestures.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Importar librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functions as fn\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn (ML en python)\n",
    "## Procesar el dataset\n",
    "from sklearn.model_selection import LeaveOneGroupOut # LeavePGroupsOut\n",
    "## Modelos ML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## Evaluación de los modelos\n",
    "from sklearn.metrics import *\n",
    "\n",
    "## Hiperparametrizacion\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "## Seleccion de variables\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Explicacion \n",
    "from sklearn import tree # visualizar dtree\n",
    "import shap\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import joblib\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Importar datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe de los datos en bruto\n",
    "df_raw = pd.read_csv('../Resultados/raw_pacientes.csv', dtype=object)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Funciones creadas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el archivo `functions.py` se ha creado la siguiente función:\n",
    "<small>\n",
    "```python\n",
    "def calcular_distancia(df: pd.DataFrame, joint_a: str, joint_b: str):\n",
    "    # Extraer posiciones de los keypoints\n",
    "    positions = df.set_index('JointName')[['3D_X', '3D_Y', '3D_Z']].loc[[joint_a, joint_b]]\n",
    "\n",
    "    # Convertir las posiciones a tipo numérico\n",
    "    positions = positions.apply(pd.to_numeric)\n",
    "\n",
    "    # Vector u (joint_a to joint_b) y Vector v (joint_b to joint_c)\n",
    "    u = np.array([positions.iloc[1, 0] - positions.iloc[0, 0],\n",
    "                  positions.iloc[1, 1] - positions.iloc[0, 1],\n",
    "                  positions.iloc[1, 2] - positions.iloc[0, 2]])\n",
    "\n",
    "    modulo_u = np.linalg.norm(u)\n",
    "\n",
    "    return modulo_u\n",
    "```\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir en test y train df_gestures\n",
    "def split_df_gestures(df:pd.DataFrame, target: str):\n",
    "\n",
    "    # Selecciona los datos de prueba (varios sujetos)\n",
    "    test_df = df.loc[(df.SubjectID==102) | (df.SubjectID==105) | (df.SubjectID==201) |\n",
    "                (df.SubjectID==202) | (df.SubjectID==205) | (df.SubjectID==302)] \n",
    "\n",
    "    # Selecciona los datos de entrenamiento excluyendo los mismos sujetos\n",
    "    train_df = df.loc[(df.SubjectID!=102) & (df.SubjectID!=105)  & (df.SubjectID!=201) &\n",
    "                    (df.SubjectID!=202) & (df.SubjectID!=205) & (df.SubjectID!=302)]\n",
    "\n",
    "    # Separa las características y las etiquetas en el conjunto de entrenamiento\n",
    "    X_train = train_df.drop([target], axis=1)  \n",
    "    y_train = pd.DataFrame(train_df[target])   \n",
    "\n",
    "    # Separa las características y las etiquetas en el conjunto de prueba\n",
    "    X_test = test_df.drop([target], axis=1)  \n",
    "    y_test = pd.DataFrame(test_df[target])   \n",
    "\n",
    "    # Convierte los DataFrames de etiquetas a arrays 1D\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    # Devuelve los conjuntos de entrenamiento y prueba\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Caracterización previa de los movimientos y Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Malla de hiperparámetros***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [KNeighborsClassifier()],\n",
    "        'classifier__n_neighbors': [2, 3, 5], \n",
    "        'classifier__weights': ['uniform', 'distance'], \n",
    "        'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  \n",
    "    },\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [GaussianNB()],\n",
    "        'classifier__var_smoothing': np.logspace(0, -8, num=100)\n",
    "    },\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [SVC(probability=True)],\n",
    "        'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'classifier__C': [0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [200, 300],\n",
    "        'classifier__max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [LogisticRegression(max_iter=500)],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'balance_data': [SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0)),\n",
    "                         SMOTEENN(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))],\n",
    "        'balance_data__smote__k_neighbors': [3, 4],\n",
    "        'select_features__k': list(range(5, 15)),\n",
    "        'classifier': [MLPClassifier()],\n",
    "        'classifier__hidden_layer_sizes': [(2,3,2), (5,10,5), (10,20,10), (15,25,15), (20,30,20)],\n",
    "        'classifier__activation': ['relu', 'tanh', 'logistic'],\n",
    "        'classifier__solver': ['sgd', 'adam'],\n",
    "        'classifier__alpha': [0.0001, 0.001, 0.01, 0.05, 0.1],\n",
    "        'classifier__learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Bucle para recorrer los gestos***\n",
    "<small>\n",
    "1. Caracterización de movimientos: calcular ángulos y disntancias dependiendo del gesto.\n",
    "2. Crear pipeline con: técnica de balanceo de datos, selección de características y algoritmo de clasificación\n",
    "3. Hiperparametrización con RandomSearchCV (con LOGO)\n",
    "4. Evaluación: F1-score, informe y curva ROC\n",
    "5. Explicación global: violin plots, visualización de cálculos internos, Permutation Importance y SHAP\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = df_raw['GestureName'].unique()\n",
    "logo = LeaveOneGroupOut()\n",
    "results = []\n",
    "gesture_name_mapping = {\n",
    "    'EFL': 'Flexión del codo izquierdo',\n",
    "    'EFR': 'Flexión del codo derecho',\n",
    "    'SFL': 'Flexión del hombro izquierdo',\n",
    "    'SFR': 'Flexión del hombro derecho',\n",
    "    'SAL': 'Abducción del hombro izquierdo',\n",
    "    'SAR': 'Abducción del hombro derecho',\n",
    "    'SFE': 'Elevación frontal del hombro',\n",
    "    'STL': 'Toque lateral izquierdo',\n",
    "    'STR': 'Toque lateral derecho'\n",
    "}\n",
    "\n",
    "for gesture in gestures:\n",
    "    df_gesture = df_raw[df_raw['GestureName'] == gesture]\n",
    "    gesture_name = gesture_name_mapping.get(gesture)\n",
    "\n",
    "    calculations = []\n",
    "\n",
    "    # ------ 1. Caracterización de movimientos ------ \n",
    "    # gestos con brazo izquierdo\n",
    "    if gesture == 'EFL' or gesture == 'SFL' or gesture == 'SAL' or gesture == 'SFE':\n",
    "        for _, group in df_gesture.groupby(np.arange(len(df_gesture)) // 25):\n",
    "            additional_data = group.iloc[0][['SubjectID', 'GestureLabel', 'GestureName',\n",
    "                                             'RepetitionNumber', 'CorrectLabel']]\n",
    "\n",
    "            left_arm_angle = fn.calculate_angle(group, 'ShoulderLeft', 'ElbowLeft', 'WristLeft')\n",
    "            left_armpit_angle = fn.calculate_angle(group, 'HipLeft', 'ShoulderLeft', 'ElbowLeft')\n",
    "            left_wrist_angle = fn.calculate_angle(group, 'ElbowLeft', 'WristLeft', 'HandLeft')\n",
    "            left_wrist_vertical_angle = fn.calculate_angle(group, 'SpineBase', 'SpineShoulder', 'WristLeft')\n",
    "            left_elbow_vertical_angle = fn.calculate_angle(group, 'SpineBase', 'SpineShoulder', 'ElbowLeft')\n",
    "            left_shoulder_angle = fn.calculate_angle(group, 'ShoulderLeft', 'SpineShoulder', 'ElbowLeft')\n",
    "\n",
    "            shoulders_distance = fn.calcular_distancia(group, 'ShoulderLeft', 'ShoulderRight')\n",
    "            hips_distance = fn.calcular_distancia(group, 'HipLeft', 'HipRight')\n",
    "            foots_distance = fn.calcular_distancia(group, 'FootLeft', 'FootRight')\n",
    "            head_distance = fn.calcular_distancia(group, 'SpineShoulder', 'Head')\n",
    "\n",
    "            calculations.append({\n",
    "                **additional_data,\n",
    "                'LeftArmAngle': left_arm_angle,\n",
    "                'LeftArmpitAngle': left_armpit_angle,\n",
    "                'LeftWristAngle': left_wrist_angle,\n",
    "                'LeftWristVerticalAngle': left_wrist_vertical_angle,\n",
    "                'LeftElbowVerticalAngle': left_elbow_vertical_angle,\n",
    "                'LeftShoulderAngle': left_shoulder_angle,\n",
    "                'ShouldersDistance': shoulders_distance,\n",
    "                'HipsDistance': hips_distance,\n",
    "                'FootsDistance': foots_distance,\n",
    "                'HeadDistance': head_distance\n",
    "            })\n",
    "\n",
    "    # gestos con brazo derecho\n",
    "    elif gesture == 'EFR'or gesture == 'SFR' or gesture == 'SAR':\n",
    "        for _, group in df_gesture.groupby(np.arange(len(df_gesture)) // 25):\n",
    "            additional_data = group.iloc[0][['SubjectID', 'GestureLabel', 'GestureName',\n",
    "                                             'RepetitionNumber', 'CorrectLabel']]\n",
    "\n",
    "            right_arm_angle = fn.calculate_angle(group, 'ShoulderRight', 'ElbowRight', 'WristRight')\n",
    "            right_armpit_angle = fn.calculate_angle(group, 'HipRight', 'ShoulderRight', 'ElbowRight')\n",
    "            right_wrist_angle = fn.calculate_angle(group, 'ElbowRight', 'WristRight', 'HandRight')\n",
    "            right_wrist_vertical_angle = fn.calculate_angle(group, 'SpineBase', 'SpineShoulder', 'WristRight')\n",
    "            right_elbow_vertical_angle = fn.calculate_angle(group, 'SpineBase', 'SpineShoulder', 'ElbowRight')\n",
    "            right_shoulder_angle = fn.calculate_angle(group, 'ShoulderRight', 'SpineShoulder', 'ElbowRight')\n",
    "\n",
    "            shoulder_distance = fn.calcular_distancia(group, 'ShoulderLeft', 'ShoulderRight')\n",
    "            hips_distance = fn.calcular_distancia(group, 'HipLeft', 'HipRight')\n",
    "            foots_distance = fn.calcular_distancia(group, 'FootLeft', 'FootRight')\n",
    "\n",
    "            calculations.append({\n",
    "                **additional_data,\n",
    "                'RightArmAngle': right_arm_angle,\n",
    "                'RightArmpitAngle': right_armpit_angle,\n",
    "                'RightWristAngle': right_wrist_angle,\n",
    "                'RightWristVerticalAngle': right_wrist_vertical_angle,\n",
    "                'RightElbowVerticalAngle': right_elbow_vertical_angle,\n",
    "                'RightShoulderAngle': right_shoulder_angle,\n",
    "                'ShouldersDistance': shoulder_distance,\n",
    "                'HipsDistance': hips_distance,\n",
    "                'FootsDistance': foots_distance,\n",
    "                'HeadDistance': head_distance\n",
    "            })\n",
    "    \n",
    "    # gestos con pierna izquierda\n",
    "    elif gesture == 'STL':\n",
    "        for _, group in df_gesture.groupby(np.arange(len(df_gesture)) // 25):\n",
    "            additional_data = group.iloc[0][['SubjectID', 'GestureLabel', 'GestureName',\n",
    "                                             'RepetitionNumber', 'CorrectLabel']]\n",
    "\n",
    "            hip_angle_left = fn.calculate_angle(group, 'HipLeft', 'SpineBase', 'KneeLeft')\n",
    "            knee_angle_left = fn.calculate_angle(group, 'HipLeft', 'KneeLeft', 'AnkleLeft')\n",
    "            ankle_angle_left = fn.calculate_angle(group, 'KneeLeft', 'AnkleLeft', 'FootLeft')\n",
    "            between_knees_angle = fn.calculate_angle(group, 'KneeLeft', 'SpineBase', 'KneeRight')\n",
    "            between_ankles_angle = fn.calculate_angle(group, 'AnkleLeft', 'SpineBase', 'AnkleRight')\n",
    "            between_foots_angle = fn.calculate_angle(group, 'FootLeft', 'SpineBase', 'FootRight')\n",
    "\n",
    "            elbows_distance = fn.calcular_distancia(group, 'ShoulderLeft', 'ShoulderRight')\n",
    "            head_distance = fn.calcular_distancia(group, 'SpineShoulder', 'Head')\n",
    "\n",
    "            calculations.append({\n",
    "                **additional_data,\n",
    "                'HipAngleLeft': hip_angle_left,\n",
    "                'KneeAngleLeft': knee_angle_left,\n",
    "                'AnkleAngleLeft': ankle_angle_left,\n",
    "                'BetweenKneesAngle': between_knees_angle,\n",
    "                'BetweenAnkleAngle': between_ankles_angle,\n",
    "                'BetweenFootsAngle': between_foots_angle,\n",
    "                'ShouldersDistance': shoulder_distance,\n",
    "                'HeadDistance': head_distance\n",
    "            })\n",
    "    \n",
    "    # gestos con pierna derecha\n",
    "    elif gesture == 'STR':\n",
    "        for _, group in df_gesture.groupby(np.arange(len(df_gesture)) // 25):\n",
    "            additional_data = group.iloc[0][['SubjectID', 'GestureLabel', 'GestureName',\n",
    "                                             'RepetitionNumber', 'CorrectLabel']]\n",
    "\n",
    "            hip_angle_right = fn.calculate_angle(group, 'HipRight', 'SpineBase', 'KneeRight')\n",
    "            knee_angle_right = fn.calculate_angle(group, 'HipRight', 'KneeRight', 'AnkleRight')\n",
    "            ankle_angle_right = fn.calculate_angle(group, 'KneeRight', 'AnkleRight', 'FootRight')\n",
    "            between_knees_angle = fn.calculate_angle(group, 'KneeLeft', 'SpineBase', 'KneeRight')\n",
    "            between_ankles_angle = fn.calculate_angle(group, 'AnkleLeft', 'SpineBase', 'AnkleRight')\n",
    "            between_foots_angle = fn.calculate_angle(group, 'FootLeft', 'SpineBase', 'FootRight')\n",
    "\n",
    "            shoulder_distance = fn.calcular_distancia(group, 'ShoulderLeft', 'ShoulderRight')\n",
    "            head_distance = fn.calcular_distancia(group, 'SpineShoulder', 'Head')\n",
    "\n",
    "            calculations.append({\n",
    "                **additional_data,\n",
    "                'HipAngleRight': hip_angle_right,\n",
    "                'KneeAngleRight': knee_angle_right,\n",
    "                'AnkleAngleRight': ankle_angle_right,\n",
    "                'BetweenKneesAngle': between_knees_angle,\n",
    "                'BetweenAnkleAngle': between_ankles_angle,\n",
    "                'BetweenFootsAngle': between_foots_angle,\n",
    "                'ShouldersDistance': shoulder_distance,\n",
    "                'HeadDistance': head_distance\n",
    "            })\n",
    "\n",
    "    df_calculations = pd.DataFrame(calculations)\n",
    "\n",
    "    #  Cálculos estadísticos para agrupar por repeticion \n",
    "    groups = df_calculations.groupby([\"SubjectID\", \"RepetitionNumber\"])\n",
    "    data = []\n",
    "\n",
    "\n",
    "    for (subject_id, repetition_number), group in groups:\n",
    "        # Selecciona solo las columnas que contienen los ángulos \n",
    "        df_calculations = group.iloc[:, 5:]\n",
    "\n",
    "        # Separar en ángulos y distancias\n",
    "        distance_columns = df_calculations.filter(regex=r'\\b.*Distance\\b').columns\n",
    "        df_angles = df_calculations.drop(columns=distance_columns)\n",
    "\n",
    "        # Calculos estadísticos\n",
    "        means = df_angles.mean()\n",
    "\n",
    "        data.append({\n",
    "            'SubjectID': subject_id,\n",
    "            'RepetitionNumber': repetition_number,\n",
    "            'CorrectLabel': group['CorrectLabel'].iloc[0],\n",
    "            'Duration': len(group),  # Duración en número de frames\n",
    "            'standardDeviation': df_calculations.std(),\n",
    "            'Maximum': df_angles.max(),\n",
    "            'Minimum': df_angles.min(),\n",
    "            'Mean': means,\n",
    "            'Range': df_angles.max() - df_angles.min(),\n",
    "            'Variance': df_angles.var(),\n",
    "            'CoV': df_angles.std() / means,  # Coeficiente de variación\n",
    "            'Skewness': df_angles.skew(),  # Asimetría\n",
    "            'Kurtosis': df_angles.kurtosis()  # Curtosis\n",
    "        })\n",
    "\n",
    "    # ordenar y formatear df\n",
    "    df_stats = pd.DataFrame(data)\n",
    "    df_stats = df_stats.apply(pd.to_numeric, errors='ignore')\n",
    "    df_stats = df_stats.sort_values(['RepetitionNumber'])\n",
    "\n",
    "    columnas = ['standardDeviation', 'Maximum', 'Minimum', 'Mean', 'Range',\n",
    "                    'Variance', 'CoV', 'Skewness', 'Kurtosis']\n",
    "    nuevas_columnas = pd.concat([fn.formatear_columnas(df_stats[col], col)\n",
    "                                 for col in columnas], axis=1)\n",
    "    df_stats = pd.concat([df_stats, nuevas_columnas], axis=1)\n",
    "    df_stats = df_stats.drop(columnas, axis=1)\n",
    "\n",
    "    # cambiar las poorly executed to incorrectly executed\n",
    "    df_stats.loc[df_stats['CorrectLabel'] == 3, 'CorrectLabel'] = 2\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = split_df_gestures(df_stats, 'CorrectLabel')\n",
    "    print(f'\\n------------ CLASIFICACION GESTO {gesture} ({gesture_name}) -----------\\n')\n",
    "\n",
    "    #  ------ 2. Crear el pipeline ------ \n",
    "    pipeline = ImbPipeline([\n",
    "        ('balance_data', SMOTETomek(smote=SMOTE(k_neighbors=2, sampling_strategy=1.0))),\n",
    "        ('select_features', SelectKBest(score_func=f_classif)),\n",
    "        ('classifier', KNeighborsClassifier(n_neighbors=2))\n",
    "    ])\n",
    "    \n",
    "    # mejores hiperparámetros\n",
    "    random = RandomizedSearchCV(pipeline, param_grid, cv=logo, n_jobs=-1, n_iter=15, scoring='roc_auc')\n",
    "    random.fit(X_train, y_train, groups=X_train['SubjectID'])\n",
    "    \n",
    "    # Mejor pipeline encontrado\n",
    "    best_pipeline = random.best_estimator_\n",
    "    print(best_pipeline)\n",
    "\n",
    "    # ------  3. Evaluar el modelo ------ \n",
    "    f1_score_train = best_pipeline.score(X_train, y_train)\n",
    "    f1_score_test = best_pipeline.score(X_test, y_test)\n",
    "    print(f'F1-score del conjunto de entrenamiento: {f1_score_train}')\n",
    "    prediction = best_pipeline.predict(X_test)\n",
    "    print(\"Informe de clasificación (conjunto de prueba):\")\n",
    "    print(classification_report(y_test, prediction)) \n",
    "    \n",
    "    # Calcular la curva ROC\n",
    "    y_prob = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label=2)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Graficar la curva ROC\n",
    "    plt.figure(figsize=(4, 3))  \n",
    "    plt.plot(fpr, tpr, label=f'Curva ROC (área = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(f'Curva ROC (gesto {gesture})')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Matriz de confusión\n",
    "    prediction = best_pipeline.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "    cm_df = pd.DataFrame(cm, index=['correcto', 'incorrecto'], columns=['correcto', 'incorrecto'])\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    ax = sns.heatmap(cm_df, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "    ax.set_title(f'Matriz de confusión de {gesture}')\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    plt.show()\n",
    "\n",
    "    # ------  4. Explicación global ------ \n",
    "    # Variables seleccionadas\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    select_kbest = best_pipeline.named_steps['select_features']\n",
    "    selected_features_mask = select_kbest.get_support()\n",
    "    selected_features = feature_names[selected_features_mask]\n",
    "    selected_features = [name.replace('remainder__', '') for name in selected_features]\n",
    "    selected_features = [name.replace('encoder__', '') for name in selected_features]\n",
    "\n",
    "    df_selected = df_stats[selected_features]\n",
    "  \n",
    "    y = df_stats['CorrectLabel'] \n",
    "    y_mapped = y.map({1: 'Correcto', 2: 'Incorrecto'})\n",
    "\n",
    "    # Violin plots\n",
    "    n_features = len(selected_features)\n",
    "    n_cols = 3  \n",
    "    n_rows = (n_features + n_cols - 1) // n_cols \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(selected_features):\n",
    "        sns.violinplot(x=y_mapped, y=df_selected[feature], ax=axes[i])\n",
    "        axes[i].set_title(f'{feature}') \n",
    "        axes[i].set_xlabel('CorrectLabel')\n",
    "        axes[i].set_ylabel(feature)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle(f'Violin plots para variables seleccionadas para el gesto {gesture_name}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])  # Prevent the supertitle from overlapping\n",
    "    plt.show()\n",
    "\n",
    "    # Visualizar los clasificadores\n",
    "    classifier = best_pipeline.named_steps['classifier']\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "\n",
    "    if classifier_name == 'GaussianNB':\n",
    "        # Extract means and variances\n",
    "        means = classifier.theta_\n",
    "        variances = classifier.var_\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 3 * n_rows))\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "        for i, feature in enumerate(selected_features):\n",
    "            axes[i].errorbar([0, 1], means[:, i], yerr=np.sqrt(variances[:, i]),\n",
    "                             fmt='o', capsize=5, color='#9b59b6', ecolor='gray')\n",
    "            for j in range(2):  \n",
    "                axes[i].text(j+0.03, means[j, i], f'{means[j, i]:.2f}', \n",
    "                     ha='left', va='center', fontsize=10, color='blue')\n",
    "            axes[i].set_title(f'{feature}')\n",
    "            axes[i].set_xticks([0, 1])\n",
    "            axes[i].set_xticklabels(['Correcto', 'Incorrecto'])\n",
    "            axes[i].set_ylabel('Media ± Std Dev')\n",
    "\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "    elif classifier_name == 'DecisionTreeClassifier':\n",
    "        fig = plt.figure(figsize=(8, 6), dpi=300) \n",
    "        tree.plot_tree(classifier,\n",
    "                        feature_names=selected_features,\n",
    "                        class_names=np.unique(y_mapped.values).astype(str),\n",
    "                        filled=True)\n",
    "\n",
    "    elif classifier_name == 'LogisticRegression':\n",
    "        coefficients = classifier.coef_[0]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(selected_features, coefficients)\n",
    "        plt.xlabel(\"Valor del coeficiente\")\n",
    "        plt.title(\"Importancia de las características en la regresión logística\")\n",
    "        plt.axvline(x=0, color=\"grey\", linestyle=\"--\")\n",
    "      \n",
    "    elif classifier_name == 'RandomForestClassifier':\n",
    "        fig, axes = plt.subplots(nrows = 1,ncols = 5,figsize = (10,2), dpi=900)\n",
    "        for index in range(0, 5):\n",
    "            tree.plot_tree(classifier.estimators_[index],\n",
    "                        feature_names=selected_features, \n",
    "                        class_names=np.unique(y_mapped.values).astype(str),\n",
    "                        filled = True,\n",
    "                        ax = axes[index])\n",
    "        axes[index].set_title('Estimator: ' + str(index), fontsize = 11)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    elif classifier_name == 'SVC' and classifier.kernel == 'linear':\n",
    "        weights = classifier.coef_[0]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(selected_features, weights, color='blue')\n",
    "        plt.axvline(x=0, color='grey', linestyle='--')\n",
    "        plt.xlabel(\"Valor del peso (Importancia de la característica)\")\n",
    "        plt.title(\"Importancia de las características en el clasificador SVC\")\n",
    "\n",
    "    fig.suptitle(f'Importancia de las variables para {classifier_name}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])  # Prevent the supertitle from overlappinge\n",
    "    plt.show()\n",
    "\n",
    "    # Permutation Importance\n",
    "    perm_importance = permutation_importance(classifier, df_selected, y, scoring='f1',n_repeats=10)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    plt.barh(range(len(sorted_idx)), perm_importance.importances_mean[sorted_idx], align='center')\n",
    "    plt.yticks(range(len(sorted_idx)), np.array(df_selected.columns)[sorted_idx])\n",
    "    plt.title(f'Permutation Importance of {gesture}')\n",
    "    plt.show()\n",
    "\n",
    "    #SHAP\n",
    "    # X100 = shap.utils.sample(df_selected, 100)\n",
    "    # explainer = shap.Explainer(classifier.predict, X100)\n",
    "    # shap_values = explainer(df_selected)\n",
    "    # shap.plots.beeswarm(shap_values)\n",
    "\n",
    "    explainer = shap.Explainer(classifier.predict, df_selected)\n",
    "    shap_values = explainer(df_selected)\n",
    "    shap.plots.beeswarm(shap_values)\n",
    "\n",
    "    # Guardar resultados evaluacion\n",
    "    results.append({\n",
    "        'Gesto': gesture,\n",
    "        'Classifier': classifier_name,\n",
    "        'K': select_kbest.k,\n",
    "        'F1-score train': f1_score_train,\n",
    "        'F1-score test': f1_score_test,\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "\n",
    "    # ------ Guardar el pipeline entrenado --------\n",
    "    filename = f'../Resultados/modelo_{gesture}.sav'\n",
    "    joblib.dump(best_pipeline, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***• Resumen resultados***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
